{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pallamadhavi/madhaviMasterThesis/blob/main/LLM_Response_PatternMining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giving this prompt along with the Dataset to LLM\n",
        "\n",
        "**Prompt:**\n",
        "Give me FPGrowth algorithm code to extract frequent patterns from the Transactional dataset i have provided."
      ],
      "metadata": {
        "id": "OAqVhzs7n78e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepSeek Response\n"
      ],
      "metadata": {
        "id": "dMWtKylyfI9i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "w65xRllqbqwP",
        "outputId": "d7f089b5-4cd8-49f9-9891-b0d8cd9bf842"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "'(' was never closed (ipython-input-8-3967235863.py, line 89)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-8-3967235863.py\"\u001b[0;36m, line \u001b[0;32m89\u001b[0m\n\u001b[0;31m    frequent_items = OrderedDict(sorted(frequent_items.items(),\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict, OrderedDict\n",
        "\n",
        "class TreeNode:\n",
        "    def __init__(self, name, count, parent):\n",
        "        self.name = name  # item name\n",
        "        self.count = count  # count\n",
        "        self.parent = parent  # parent node\n",
        "        self.children = {}  # children nodes\n",
        "        self.next = None  # link to next node with same name\n",
        "\n",
        "    def increment(self, count):\n",
        "        self.count += count\n",
        "\n",
        "class FPTree:\n",
        "    def __init__(self, min_support):\n",
        "        self.root = TreeNode(None, 0, None)\n",
        "        self.header_table = {}\n",
        "        self.min_support = min_support\n",
        "        self.frequent_items = set()\n",
        "\n",
        "    def _update_header_table(self, item, node):\n",
        "        if item in self.header_table:\n",
        "            current = self.header_table[item]\n",
        "            while current.next is not None:\n",
        "                current = current.next\n",
        "            current.next = node\n",
        "        else:\n",
        "            self.header_table[item] = node\n",
        "\n",
        "    def insert_transaction(self, transaction, count=1):\n",
        "        current_node = self.root\n",
        "\n",
        "        for item in transaction:\n",
        "            if item in current_node.children:\n",
        "                current_node.children[item].increment(count)\n",
        "            else:\n",
        "                new_node = TreeNode(item, count, current_node)\n",
        "                current_node.children[item] = new_node\n",
        "                self._update_header_table(item, new_node)\n",
        "\n",
        "            current_node = current_node.children[item]\n",
        "\n",
        "    def _find_prefix_paths(self, item):\n",
        "        paths = []\n",
        "        node = self.header_table[item]\n",
        "\n",
        "        while node is not None:\n",
        "            prefix_path = []\n",
        "            current = node.parent\n",
        "            while current.name is not None:\n",
        "                prefix_path.append(current.name)\n",
        "                current = current.parent\n",
        "            if prefix_path:\n",
        "                paths.append((prefix_path, node.count))\n",
        "            node = node.next\n",
        "\n",
        "        return paths\n",
        "\n",
        "    def _mine_tree(self, suffix, frequent_itemsets):\n",
        "        items = [item for item in self.header_table.keys()]\n",
        "        items.sort(key=lambda x: self.header_table[x].count, reverse=True)\n",
        "\n",
        "        for item in items:\n",
        "            new_suffix = suffix.copy()\n",
        "            new_suffix.add(item)\n",
        "            frequent_itemsets.append((new_suffix, self.header_table[item].count))\n",
        "\n",
        "            conditional_patterns = self._find_prefix_paths(item)\n",
        "            conditional_tree = FPTree(self.min_support)\n",
        "\n",
        "            for pattern, count in conditional_patterns:\n",
        "                conditional_tree.insert_transaction(pattern, count)\n",
        "\n",
        "            if conditional_tree.header_table:\n",
        "                conditional_tree._mine_tree(new_suffix, frequent_itemsets)\n",
        "\n",
        "def preprocess_data(transactions, min_support):\n",
        "    item_counts = defaultdict(int)\n",
        "\n",
        "    # Count item frequencies\n",
        "    for transaction in transactions:\n",
        "        for item in transaction:\n",
        "            item_counts[item] += 1\n",
        "\n",
        "    # Filter items below min support and sort by frequency\n",
        "    frequent_items = {item: count for item, count in item_counts.items()\n",
        "                     if count >= min_support}\n",
        "    frequent_items = OrderedDict(sorted(frequent_items.items(),\n",
        "                                     key=lambda x: (-x[1], x[0]))\n",
        "\n",
        "    # Filter and sort transactions\n",
        "    processed_transactions = []\n",
        "    for transaction in transactions:\n",
        "        filtered = [item for item in transaction if item in frequent_items]\n",
        "        filtered.sort(key=lambda x: (frequent_items[x], x), reverse=True)\n",
        "        if filtered:\n",
        "            processed_transactions.append(filtered)\n",
        "\n",
        "    return processed_transactions, frequent_items\n",
        "\n",
        "def fp_growth(transactions, min_support):\n",
        "    # Preprocess data\n",
        "    processed_transactions, frequent_items = preprocess_data(transactions, min_support)\n",
        "\n",
        "    # Build FP-tree\n",
        "    tree = FPTree(min_support)\n",
        "    for transaction in processed_transactions:\n",
        "        tree.insert_transaction(transaction)\n",
        "\n",
        "    # Mine frequent itemsets\n",
        "    frequent_itemsets = []\n",
        "    tree._mine_tree(set(), frequent_itemsets)\n",
        "\n",
        "    # Sort by length and then by support\n",
        "    frequent_itemsets.sort(key=lambda x: (len(x[0]), -x[1]))\n",
        "\n",
        "    return frequent_itemsets\n",
        "\n",
        "def load_transactions(file_path):\n",
        "    transactions = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            transaction = list(map(int, line.strip().split('\\t')))\n",
        "            transactions.append(transaction)\n",
        "    return transactions\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your dataset\n",
        "    transactions = load_transactions('Transactional_T10I4D100K.csv')\n",
        "\n",
        "    # Set minimum support (adjust as needed)\n",
        "    min_support = 100  # This is just an example - adjust based on your dataset size\n",
        "\n",
        "    # Run FP-Growth\n",
        "    frequent_itemsets = fp_growth(transactions, min_support)\n",
        "\n",
        "    # Display results\n",
        "    print(f\"Frequent Itemsets (min_support={min_support}):\")\n",
        "    for itemset, support in frequent_itemsets[:50]:  # Print first 50 for brevity\n",
        "        print(f\"{sorted(itemset)}: {support}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict, OrderedDict\n",
        "\n",
        "class TreeNode:\n",
        "    def __init__(self, name, count, parent):\n",
        "        self.name = name  # item name\n",
        "        self.count = count  # count\n",
        "        self.parent = parent  # parent node\n",
        "        self.children = {}  # children nodes\n",
        "        self.next = None  # link to next node with same name\n",
        "\n",
        "    def increment(self, count):\n",
        "        self.count += count\n",
        "\n",
        "class FPTree:\n",
        "    def __init__(self, min_support):\n",
        "        self.root = TreeNode(None, 0, None)\n",
        "        self.header_table = {}\n",
        "        self.min_support = min_support\n",
        "        self.frequent_items = set()\n",
        "\n",
        "    def _update_header_table(self, item, node):\n",
        "        if item in self.header_table:\n",
        "            current = self.header_table[item]\n",
        "            while current.next is not None:\n",
        "                current = current.next\n",
        "            current.next = node\n",
        "        else:\n",
        "            self.header_table[item] = node\n",
        "\n",
        "    def insert_transaction(self, transaction, count=1):\n",
        "        current_node = self.root\n",
        "\n",
        "        for item in transaction:\n",
        "            if item in current_node.children:\n",
        "                current_node.children[item].increment(count)\n",
        "            else:\n",
        "                new_node = TreeNode(item, count, current_node)\n",
        "                current_node.children[item] = new_node\n",
        "                self._update_header_table(item, new_node)\n",
        "\n",
        "            current_node = current_node.children[item]\n",
        "\n",
        "    def _find_prefix_paths(self, item):\n",
        "        paths = []\n",
        "        node = self.header_table[item]\n",
        "\n",
        "        while node is not None:\n",
        "            prefix_path = []\n",
        "            current = node.parent\n",
        "            while current.name is not None:\n",
        "                prefix_path.append(current.name)\n",
        "                current = current.parent\n",
        "            if prefix_path:\n",
        "                paths.append((prefix_path, node.count))\n",
        "            node = node.next\n",
        "\n",
        "        return paths\n",
        "\n",
        "    def _mine_tree(self, suffix, frequent_itemsets):\n",
        "        items = [item for item in self.header_table.keys()]\n",
        "        items.sort(key=lambda x: self.header_table[x].count, reverse=True)\n",
        "\n",
        "        for item in items:\n",
        "            new_suffix = suffix.copy()\n",
        "            new_suffix.add(item)\n",
        "            frequent_itemsets.append((new_suffix, self.header_table[item].count))\n",
        "\n",
        "            conditional_patterns = self._find_prefix_paths(item)\n",
        "            conditional_tree = FPTree(self.min_support)\n",
        "\n",
        "            for pattern, count in conditional_patterns:\n",
        "                conditional_tree.insert_transaction(pattern, count)\n",
        "\n",
        "            if conditional_tree.header_table:\n",
        "                conditional_tree._mine_tree(new_suffix, frequent_itemsets)\n",
        "\n",
        "def preprocess_data(transactions, min_support):\n",
        "    item_counts = defaultdict(int)\n",
        "\n",
        "    # Count item frequencies\n",
        "    for transaction in transactions:\n",
        "        for item in transaction:\n",
        "            item_counts[item] += 1\n",
        "\n",
        "    # Filter items below min support and sort by frequency\n",
        "    frequent_items = {item: count for item, count in item_counts.items()\n",
        "                     if count >= min_support}\n",
        "    frequent_items = OrderedDict(sorted(frequent_items.items(),\n",
        "                                     key=lambda x: (-x[1], x[0])))\n",
        "\n",
        "    # Filter and sort transactions\n",
        "    processed_transactions = []\n",
        "    for transaction in transactions:\n",
        "        filtered = [item for item in transaction if item in frequent_items]\n",
        "        filtered.sort(key=lambda x: (frequent_items[x], x), reverse=True)\n",
        "        if filtered:\n",
        "            processed_transactions.append(filtered)\n",
        "\n",
        "    return processed_transactions, frequent_items\n",
        "\n",
        "def fp_growth(transactions, min_support):\n",
        "    # Preprocess data\n",
        "    processed_transactions, frequent_items = preprocess_data(transactions, min_support)\n",
        "\n",
        "    # Build FP-tree\n",
        "    tree = FPTree(min_support)\n",
        "    for transaction in processed_transactions:\n",
        "        tree.insert_transaction(transaction)\n",
        "\n",
        "    # Mine frequent itemsets\n",
        "    frequent_itemsets = []\n",
        "    tree._mine_tree(set(), frequent_itemsets)\n",
        "\n",
        "    # Sort by length and then by support\n",
        "    frequent_itemsets.sort(key=lambda x: (len(x[0]), -x[1]))\n",
        "\n",
        "    return frequent_itemsets\n",
        "\n",
        "def load_transactions(file_path):\n",
        "    transactions = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            transaction = list(map(int, line.strip().split('\\t')))\n",
        "            transactions.append(transaction)\n",
        "    return transactions\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your dataset\n",
        "    transactions = load_transactions('Transactional_T10I4D100K.csv')\n",
        "\n",
        "    # Set minimum support (adjust as needed)\n",
        "    min_support = 100  # This is just an example - adjust based on your dataset size\n",
        "\n",
        "    # Run FP-Growth\n",
        "    frequent_itemsets = fp_growth(transactions, min_support)\n",
        "\n",
        "    # Display results\n",
        "    print(f\"Frequent Itemsets (min_support={min_support}):\")\n",
        "    for itemset, support in frequent_itemsets[:50]:  # Print first 50 for brevity\n",
        "        print(f\"{sorted(itemset)}: {support}\")"
      ],
      "metadata": {
        "id": "hQiV-E8XrvGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### No patterns have been discovered from the code deepseek have given."
      ],
      "metadata": {
        "id": "R4Nukx5wpTJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatgpt Response\n"
      ],
      "metadata": {
        "id": "YemRP5VvfNiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mlxtend\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvxqYJE1fPHq",
        "outputId": "31affe81-1107-4239-e406-7f77afb9be0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.15.3)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.5.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import fpgrowth\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "file_path = \"Transactional_T10I4D100K.csv\"\n",
        "\n",
        "# Step 2: Read the tab-separated transactions\n",
        "with open(file_path, 'r') as file:\n",
        "    transactions = [line.strip().split('\\t') for line in file.readlines()]\n",
        "\n",
        "# Step 3: Transform the data using TransactionEncoder\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "# Step 4: Apply FP-Growth algorithm\n",
        "min_support = 0.001  # Example: change this as needed\n",
        "frequent_itemsets = fpgrowth(df, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Step 5: Show results\n",
        "print(frequent_itemsets)\n"
      ],
      "metadata": {
        "id": "viIaBh4GfPUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### No patterns have been discovered from the code deepseek have given."
      ],
      "metadata": {
        "id": "QAzCazKApo-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini Response"
      ],
      "metadata": {
        "id": "fQb7Yfb9mp54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mlxtend"
      ],
      "metadata": {
        "id": "IELeYbWdmtL7",
        "outputId": "00e2feab-22cc-42d4-af69-5bcd4d8621f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.15.3)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.5.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import fpgrowth\n",
        "\n",
        "# Read the file line by line, splitting by tab delimiter\n",
        "# This assumes each transaction is on a new line and items within a transaction are separated by tabs.\n",
        "transactions = []\n",
        "with open('Transactional_T10I4D100K.csv', 'r') as f:\n",
        "    for line in f:\n",
        "        # Strip leading/trailing whitespace and split by tab delimiter\n",
        "        items = line.strip().split('\\t')\n",
        "        transactions.append(items)\n",
        "\n",
        "# Convert the list of transactions into a one-hot encoded DataFrame.\n",
        "# This format is required by the fpgrowth function.\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "df_onehot = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "# Apply the FPGrowth algorithm to find frequent itemsets.\n",
        "# min_support: This parameter defines the minimum support threshold for an itemset to be considered 'frequent'.\n",
        "#              For example, min_support=0.01 means an itemset must appear in at least 1% of all transactions.\n",
        "#              You can adjust this value based on your needs. A higher value will result in fewer but\n",
        "#              more frequent itemsets, while a lower value will yield more itemsets, including less frequent ones.\n",
        "# use_colnames: Set to True to use the actual item names (column names) in the output, making it more readable.\n",
        "frequent_itemsets = fpgrowth(df_onehot, min_support=0.01, use_colnames=True)\n",
        "\n",
        "# Sort the frequent itemsets by their support in descending order\n",
        "frequent_itemsets = frequent_itemsets.sort_values(by='support', ascending=False)\n",
        "\n",
        "# Display the top 10 frequent itemsets.\n",
        "print(\"Top 10 Frequent Itemsets:\")\n",
        "print(frequent_itemsets.head(10))\n",
        "\n",
        "# Save all frequent itemsets to a CSV file for further analysis.\n",
        "frequent_itemsets.to_csv('frequent_itemsets.csv', index=False)\n",
        "print(\"\\nAll frequent itemsets have been saved to 'frequent_itemsets.csv'.\")"
      ],
      "metadata": {
        "id": "wecR7IkXckxD",
        "outputId": "722ef84a-87ba-4ffa-cedd-f067f98b6e04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Frequent Itemsets:\n",
            "      support itemsets\n",
            "0    0.078261    (368)\n",
            "47   0.070576    (529)\n",
            "174  0.068064    (829)\n",
            "31   0.062631    (766)\n",
            "120  0.058428    (722)\n",
            "167  0.058338    (354)\n",
            "168  0.054075    (684)\n",
            "72   0.053725    (217)\n",
            "193  0.051003    (494)\n",
            "121  0.050543    (419)\n",
            "\n",
            "All frequent itemsets have been saved to 'frequent_itemsets.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The error occured while executing the code"
      ],
      "metadata": {
        "id": "UB63b4orprEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perplexity Response"
      ],
      "metadata": {
        "id": "PADON1AOm0SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TreeNode:\n",
        "    def __init__(self, item, count, parent):\n",
        "        self.item = item          # Item name\n",
        "        self.count = count        # Frequency count\n",
        "        self.parent = parent      # Parent node reference\n",
        "        self.children = {}        # Child nodes dictionary\n",
        "        self.link = None          # Link to next node (same item)\n",
        "\n",
        "def create_tree(transactions, min_support):\n",
        "    # First pass: count item frequencies\n",
        "    header_table = {}\n",
        "    for trans in transactions:\n",
        "        for item in trans:\n",
        "            header_table[item] = header_table.get(item, 0) + 1\n",
        "\n",
        "    # Prune infrequent items\n",
        "    header_table = {k: v for k, v in header_table.items() if v >= min_support}\n",
        "    frequent_items = set(header_table.keys())\n",
        "\n",
        "    # Return empty tree if no frequent items\n",
        "    if not frequent_items:\n",
        "        return None, None\n",
        "\n",
        "    # Initialize header table with support counts and null links\n",
        "    for k in header_table:\n",
        "        header_table[k] = [header_table[k], None]\n",
        "\n",
        "    # Build FP-tree\n",
        "    root = TreeNode('Null', 1, None)\n",
        "\n",
        "    for trans in transactions:\n",
        "        # Filter and sort transaction items\n",
        "        filtered = [item for item in trans if item in frequent_items]\n",
        "        filtered.sort(key=lambda x: header_table[x][0], reverse=True)\n",
        "\n",
        "        # Update tree with current transaction\n",
        "        current = root\n",
        "        for item in filtered:\n",
        "            current = update_tree(item, current, header_table)\n",
        "\n",
        "    return root, header_table\n",
        "\n",
        "def update_tree(item, node, header_table):\n",
        "    # Create child node if doesn't exist\n",
        "    if item in node.children:\n",
        "        node.children[item].count += 1\n",
        "    else:\n",
        "        new_node = TreeNode(item, 1, node)\n",
        "        node.children[item] = new_node\n",
        "        # Link to header table\n",
        "        update_header_table(new_node, header_table[item])\n",
        "\n",
        "    return node.children[item]\n",
        "\n",
        "def update_header_table(new_node, header_entry):\n",
        "    # Update header table with new node\n",
        "    if header_entry[1] is None:\n",
        "        header_entry[1] = new_node\n",
        "    else:\n",
        "        current = header_entry[1]\n",
        "        while current.link is not None:\n",
        "            current = current.link\n",
        "        current.link = new_node\n",
        "\n",
        "def ascend_tree(node, prefix_path):\n",
        "    # Recursively ascend tree to get conditional prefix path\n",
        "    if node.parent is not None:\n",
        "        prefix_path.append(node.item)\n",
        "        ascend_tree(node.parent, prefix_path)\n",
        "\n",
        "def find_prefix_path(item, node):\n",
        "    # Find conditional pattern base for an item\n",
        "    paths = []\n",
        "    while node is not None:\n",
        "        prefix_path = []\n",
        "        ascend_tree(node, prefix_path)\n",
        "        if prefix_path:\n",
        "            paths.append((prefix_path[:-1], node.count))  # Exclude current item\n",
        "        node = node.link\n",
        "    return paths\n",
        "\n",
        "def mine_tree(header_table, min_support, prefix, frequent_itemsets):\n",
        "    # Recursively mine FP-tree for frequent itemsets\n",
        "    items = [item[0] for item in sorted(header_table.items(), key=lambda x: x[1][0])]\n",
        "\n",
        "    for item in items:\n",
        "        new_prefix = prefix.copy()\n",
        "        new_prefix.add(item)\n",
        "        support = header_table[item][0]\n",
        "        frequent_itemsets.append((new_prefix, support))\n",
        "\n",
        "        # Find conditional pattern base\n",
        "        cond_patterns = find_prefix_path(item, header_table[item][1])\n",
        "        cond_transactions = []\n",
        "        for path, count in cond_patterns:\n",
        "            cond_transactions.extend([path] * count)\n",
        "\n",
        "        # Build conditional FP-tree\n",
        "        cond_tree, cond_header = create_tree(cond_transactions, min_support)\n",
        "        if cond_header is not None:\n",
        "            mine_tree(cond_header, min_support, new_prefix, frequent_itemsets)\n",
        "\n",
        "def fpgrowth(transactions, min_support):\n",
        "    # Main function to run FP-Growth\n",
        "    root, header_table = create_tree(transactions, min_support)\n",
        "    if root is None:\n",
        "        return []\n",
        "\n",
        "    frequent_itemsets = []\n",
        "    mine_tree(header_table, min_support, set(), frequent_itemsets)\n",
        "    return frequent_itemsets\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    transactions = [\n",
        "        ['milk', 'bread', 'eggs'],\n",
        "        ['milk', 'bread'],\n",
        "        ['milk', 'diapers'],\n",
        "        ['bread', 'diapers', 'beer'],\n",
        "        ['bread', 'beer']\n",
        "    ]\n",
        "\n",
        "    min_support = 2  # Minimum support count\n",
        "    results = fpgrowth(transactions, min_support)\n",
        "\n",
        "    # Print results sorted by support\n",
        "    for itemset, support in sorted(results, key=lambda x: len(x[0])):\n",
        "        print(f\"{itemset}: {support}\")\n"
      ],
      "metadata": {
        "id": "-jO_7HG6m7Sx",
        "outputId": "05e7d64f-88a8-4cad-a329-f4f359a2f6b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'diapers'}: 2\n",
            "{'diapers'}: 2\n",
            "{'beer'}: 2\n",
            "{'beer'}: 2\n",
            "{'milk'}: 3\n",
            "{'milk'}: 2\n",
            "{'bread'}: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Created its own dataset ignoring the given transactional dataset"
      ],
      "metadata": {
        "id": "nioRFonSqDHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copilot"
      ],
      "metadata": {
        "id": "WSjvhpKgnDlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import fpgrowth\n",
        "\n",
        "# Sample transactional data (replace this with your actual dataset once it loads)\n",
        "transactions = [\n",
        "    ['milk', 'bread', 'nuts', 'apple'],\n",
        "    ['milk', 'bread', 'nuts'],\n",
        "    ['milk', 'bread'],\n",
        "    ['bread', 'nuts']\n",
        "]\n",
        "\n",
        "# Step 1: Transform the data\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "# Step 2: Apply FP-Growth\n",
        "frequent_itemsets = fpgrowth(df, min_support=0.5, use_colnames=True)\n",
        "\n",
        "# Step 3: Display results\n",
        "print(frequent_itemsets)\n"
      ],
      "metadata": {
        "id": "46rtSqQmnE8l",
        "outputId": "faee8b29-65ae-4633-f8da-c27747247683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   support             itemsets\n",
            "0     1.00              (bread)\n",
            "1     0.75               (nuts)\n",
            "2     0.75               (milk)\n",
            "3     0.75        (nuts, bread)\n",
            "4     0.75        (milk, bread)\n",
            "5     0.50         (milk, nuts)\n",
            "6     0.50  (milk, nuts, bread)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Created its own dataset ignoring the given transactional dataset"
      ],
      "metadata": {
        "id": "cCGiIUEgxk0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PAMI GPT"
      ],
      "metadata": {
        "id": "mOwQM5yrnGYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PAMI\n"
      ],
      "metadata": {
        "id": "yNqtOLgonFYt",
        "outputId": "11493d20-a4c4-4f59-b246-9a5c1da10c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PAMI in /usr/local/lib/python3.11/dist-packages (2025.6.26.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from PAMI) (5.9.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from PAMI) (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from PAMI) (5.24.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from PAMI) (3.10.0)\n",
            "Requirement already satisfied: resource in /usr/local/lib/python3.11/dist-packages (from PAMI) (0.2.1)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.11/dist-packages (from PAMI) (0.35.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from PAMI) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from PAMI) (11.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from PAMI) (2.0.2)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.11/dist-packages (from PAMI) (8.2.3)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.11/dist-packages (from PAMI) (3.0.2)\n",
            "Requirement already satisfied: discord.py in /usr/local/lib/python3.11/dist-packages (from PAMI) (2.5.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from PAMI) (3.5)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from PAMI) (1.2.18)\n",
            "Requirement already satisfied: fastparquet in /usr/local/lib/python3.11/dist-packages (from PAMI) (2024.11.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->PAMI) (1.17.2)\n",
            "Requirement already satisfied: aiohttp<4,>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from discord.py->PAMI) (3.11.15)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet->PAMI) (2.10.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from fastparquet->PAMI) (2025.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastparquet->PAMI) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->PAMI) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->PAMI) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->PAMI) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->PAMI) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->PAMI) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->PAMI) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->PAMI) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->PAMI) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->PAMI) (8.5.0)\n",
            "Requirement already satisfied: JsonForm>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from resource->PAMI) (0.0.2)\n",
            "Requirement already satisfied: JsonSir>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from resource->PAMI) (0.0.2)\n",
            "Requirement already satisfied: python-easyconfig>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from resource->PAMI) (0.1.7)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (3.1.6)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (2.19.2)\n",
            "Requirement already satisfied: docutils<0.22,>=0.20 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (0.21.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (2.32.3)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx->PAMI) (3.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.11/dist-packages (from sphinx-rtd-theme->PAMI) (4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py->PAMI) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py->PAMI) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py->PAMI) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py->PAMI) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py->PAMI) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py->PAMI) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py->PAMI) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1->sphinx->PAMI) (3.0.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from JsonForm>=0.0.2->resource->PAMI) (4.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->PAMI) (1.17.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from python-easyconfig>=0.1.0->resource->PAMI) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx->PAMI) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx->PAMI) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx->PAMI) (2025.6.15)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->JsonForm>=0.0.2->resource->PAMI) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->JsonForm>=0.0.2->resource->PAMI) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->JsonForm>=0.0.2->resource->PAMI) (0.25.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->JsonForm>=0.0.2->resource->PAMI) (4.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import the FPGrowth class from PAMI\n",
        "import PAMI.frequentPattern.basic.FPGrowth as alg\n",
        "\n",
        "# Step 2: Specify your input file\n",
        "input_file = \"/content/Transactional_T10I4D100K.csv\"\n",
        "output_file = \"fp_growth_patterns.txt\"\n",
        "min_sup = 10  # You can also use a float value between 0â€“1\n",
        "\n",
        "# Step 3: Create the FPGrowth object\n",
        "fpg = alg.FPGrowth(input_file, min_sup)\n",
        "\n",
        "# Step 4: Start the mining process\n",
        "fpg.mine()\n",
        "\n",
        "# Step 5: Fetch and print the frequent patterns\n",
        "patterns = fpg.getPatterns()\n",
        "print(\"Total number of Frequent Patterns:\", len(patterns))\n",
        "\n",
        "# Step 6: Save the results to a file\n",
        "fpg.save(output_file)\n",
        "\n",
        "# Step 7: Print runtime and memory usage\n",
        "print(\"Runtime (seconds):\", fpg.getRuntime())\n",
        "print(\"Memory USS (bytes):\", fpg.getMemoryUSS())\n",
        "print(\"Memory RSS (bytes):\", fpg.getMemoryRSS())\n"
      ],
      "metadata": {
        "id": "4Z8kG7w1nVwB",
        "outputId": "3c444d3c-fb24-4575-9452-32150b39b846",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent patterns were generated successfully using frequentPatternGrowth algorithm\n",
            "Total number of Frequent Patterns: 410666\n",
            "Runtime (seconds): 25.846738815307617\n",
            "Memory USS (bytes): 772362240\n",
            "Memory RSS (bytes): 792420352\n"
          ]
        }
      ]
    }
  ]
}